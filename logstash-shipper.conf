# Where to get input
input {
  # syslog inputs
  tcp {
    port => 5000
    type => "syslog"
  }
  udp {
    port => 5000
    type => "syslog"
  }

  # Lumberjack input
  lumberjack {
    port => 5002
    ssl_certificate => "/etc/logstash/ssl/logstash-forwarder.crt"
    ssl_key => "/etc/logstash/ssl/logstash-forwarder.key"
    type => "lumberjack"
  }

  # CoreOS journal input
  tcp {
    codec => "json_lines"
    port => 5004
    tags => ["coreos","docker"]
    type => "systemd"
  }

  # Logspout input
  tcp {
    codec => "json_lines"
    port => 5006
    tags => ["docker"]
    type => "logspout"
  }

  # Log4j application input
  log4j {
    codec => "json_lines"
    port  => 4560
    tags  => ["applogs"]
    type  => "log4j"
  }
}

# Some Filtering
filter {
  # syslog filter
  if [type] == "syslog" {
    grok {
      match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
      add_field => [ "received_at", "%{@timestamp}" ]
      add_field => [ "received_from", "%{host}" ]
    }
    syslog_pri { }
    date {
      match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
    }

    if !("_grokparsefailure" in [tags]) {
      mutate {
        replace => [ "message", "%{syslog_message}" ]
      }

      mutate {
        remove_field => [  "syslog_message" ]
      }
    }

    # Remove spurious fields that have names changed or been aggregated
    mutate {
      remove_field => [ "syslog_hostname", "syslog_timestamp" ]
    }
  }

  # systemd/journal filter (CoreOS)
  if [type] == "systemd" {
    mutate { rename => [ "MESSAGE", "message" ] }
    mutate { rename => [ "_SYSTEMD_UNIT", "program" ] }
  }

  # Logspout/Docker filter
  if [type] == "logspout" {
    grok {
      match => { "message" => "%{SYSLOG5424PRI}%{NONNEGINT:ver} +(?:%{TIMESTAMP_ISO8601:ts}|-) +(?:%{HOSTNAME:containerid}|-) +(?:%{NOTSPACE:containername}|-) +(?:%{NOTSPACE:proc}|-) +(?:%{WORD:msgid}|-) +(?:%{SYSLOG5424SD:sd}|-|) +%{GREEDYDATA:msg}" } 
    }
    syslog_pri { }
    date {
      match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
    }

    if !("_grokparsefailure" in [tags]) {
      mutate {
        replace => [ "@source_host", "%{syslog_hostname}" ]
        replace => [ "@message", "%{syslog_message}" ]
      }
    }

    # Remove spurious fields that have names changed or been aggregated
    mutate {
      remove_field => [ "syslog_hostname", "syslog_message", "syslog_timestamp" ]
    }
  }
}

# Where to send output
output {
  # Redis queue output
  redis {
    data_type => "list"
  # host => ["localhost:6379"]
    host => ["REDIS_CONN_STR"]
    key => "logstash"
    codec => "json"
  }

  # Kafka queue output
#  kafka {
   # broker_list => ["localhost:9092"]
#    broker_list => ["KAFKA_BROKERS"]
#    codec => "json"
#    compression_codec => "snappy"
#    topic_id => "logstash"
   # host => ["localhost:6379"]
#    host => ["KAFKA_CONN_STR"]
#  }
}
